---
layout:     post
title:      caffe 源码学习
subtitle:   study caffe
date:       2019-03-13
author:     malixian
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - docker
    - Kubernetes
---
## caffe 源码学习
- 业余时间对caffe的源码学习，一方面学习caffe的设计，一方面也可以巩固c++基础
- 此项目包含了caffe的一些核心类，并且对一些典型的实现如卷积操作做了一些调研与分析

## 立个 flag
- 实现一个简单的caffe
- 结合k8s是否可以实现caffe的多机执行
## Caffe的核心数据结构
- Blob
- Layer
- Net
- Solver

## caffe的一些核心依赖包

- CUDA
- BLAS：高性能的现代运算库
- OpenCV
- Google：protobuffer、gfalgs、glog
- IO：Hdf5、leveldb、lmdb

## 核心数据结构解析
- Blob
Blob 抽象出了神经网络图中流动的数据，可以类似于tensorflow中的tensor数据结构
Blob类中的核心函数：
1. 通过构造函数 `explicit Blob(const vector<int>& shape); ` 确定数据的维度，构造函数中通过explicit避免隐使得转换。维度的特征可以从`explicit Blob(const int num, const int channels, const int height, const int width);`中明显的看出来，包含num（即为batch size）、channels、height、width
2. Reshape()函数，根据给定的参数改变输入blob的维度，仅改变维度但是内容不变，caffe中的四维数据通过一维的数组来表示，并使用offset内联函数来确定每个数据的位置`((n * channels() + c) * height() + h) * width() + w`
3. 一些核心的成员函数
```
  const Dtype* cpu_data() const; //cpu使用的数据
  void set_cpu_data(Dtype* data);//用数据块的值来blob里面的data。
  const Dtype* gpu_data() const;//返回不可更改的指针，下同
  const Dtype* cpu_diff() const;
  const Dtype* gpu_diff() const;
  Dtype* mutable_cpu_data();//返回可更改的指针，下同
  Dtype* mutable_gpu_data();
  Dtype* mutable_cpu_diff();
  Dtype* mutable_gpu_diff();
```
带mutable_开头的意味着可以对返回的指针内容进行更改，而不带mutable_开头的返回const 指针，不能对其指针的内容进行修改

4. 成员变量
```
  shared_ptr<SyncedMemory> data_;//原始数据
  shared_ptr<SyncedMemory> diff_;//梯度数据
  shared_ptr<SyncedMemory> shape_data_;
  vector<int> shape_;//维度信息
  int count_;//为blob的size，即总容量
  int capacity_;//类比容器就是超过容量需要重新分配内存
```
5. c++中几种类型转换
- static_cast	编译期间，用于良性转换，一般不会导致意外发生，风险很低。向上转换无信息丢失，向下转换可能有信息丢失
- const_cast	用于 const 与非 const、volatile 与非 volatile 之间的转换。
- reinterpret_cast	高度危险的转换，这种转换仅仅是对二进制位的重新解释，不会借助已有的转换规则对数据进行调整，但是可以实现最灵活的 C++ 类型转换。
- dynamic_cast	借助 RTTI，用于类型安全的向下转型（Downcasting）。

## layer 数据结构解析
- layer层的实现类型非常多，我们通过分析最原始的layer层，来查看layer的核心功能
1. 成员变量

```
/** The protobuf that stores the layer parameters */
  LayerParameter layer_param_;
  /** The phase: TRAIN or TEST */
  Phase phase_;
  /** The vector that stores the learnable parameters as a set of blobs. */
  vector<shared_ptr<Blob<Dtype> > > blobs_;
  /** Vector indicating whether to compute the diff of each param blob. */
  vector<bool> param_propagate_down_;

  /** The vector that indicates whether each top blob has a non-zero weight in
   *  the objective function. */
  vector<Dtype> loss_;

```

2. 主要的函数
    -Forward：前向传播函数inline函数，包括核心的虚函数Forward_cpu、Forward_gpu
    -Backward：反向传播函数inline函数，包括核心的虚函数Backward_cpu、Backward_gpu
    -LayerSetUp：初始化layer

3. layer 工厂函数
- layer同过多态实现了非常多种layer，由此产生的问题是在用户使用到子类的时候不得不使用到new XX的代码，因此客户端必须知道子类的名称，而且当类明修改时需要修改全部的new XX的代码。通过工厂模式可以改变此问题
- 工厂模式的分类：简单工厂（simple factory）、工厂方法(factory method)、抽象工厂(abstrct factory),此三种工厂模式的复杂度依次递增，根据业务需求选择不同的工厂模式。

4. 以卷积层为例进行分析
- 父子关系：layer->base_conv_layer->conv_layer
- base_conv_layer成员变量

```
 /// @brief The spatial dimensions of a filter kernel.
  // kernel的形状 = [kernel_h, kernel_w]
  Blob<int> kernel_shape_;

  /// @brief The spatial dimensions of the stride.
  // 步长形状 = [stride_h, stride_w]
  Blob<int> stride_;

  /// @brief The spatial dimensions of the padding.
  // pad的形状 = [pad_h, pad_w]
  Blob<int> pad_;

  /// @brief The spatial dimensions of the dilation.
  Blob<int> dilation_;

  /// @brief The spatial dimensions of the convolution input.
  // 卷积的输入形状 = [输入图像通道数, 输入图像h,    输入图像w]
  Blob<int> conv_input_shape_;

  /// @brief The spatial dimensions of the col_buffer.
  // col_buffer的形状 = [kernel_dim_, conv_out_spatial_dim_ ]
  vector<int> col_buffer_shape_;

  /// @brief The spatial dimensions of the output.
  // 输出的形状
  vector<int> output_shape_;

  // 输入的形状
  const vector<int>* bottom_shape_;

  //空间轴个数
  int num_spatial_axes_;
  // 输入度维度 = 输入图像通道数*输入图像的h*输入图像w
  int bottom_dim_;
  // 输出度维度 = 输出图像通道数*输出图像的h*输出图像w
  int top_dim_;

  // 输入图像的第几个轴是通道
  int channel_axis_;
  // batch size
  int num_;
  // 输入图像的通道数
  int channels_;
  // 卷积组的大小
  int group_;
  // 输出空间维度 = 卷积之后的图像长*卷积之后图像的宽
  int out_spatial_dim_;
  // 使用卷积组用到的
  int weight_offset_;
  // 卷积后的图像的通道数
  int num_output_;
  // 是否启用偏置
  bool bias_term_;
  // 是不是1x1卷积
  bool is_1x1_;
  // 强制使用n维通用卷积
  bool force_nd_im2col_;
  // conv_in_channels_ * conv_out_spatial_dim_
  int num_kernels_im2col_;
  // num_kernels_col2im_ = reverse_dimensions() ? top_dim_ : bottom_dim_
  int num_kernels_col2im_;

  // 卷积的输出通道数 ,在参数配置文件中设置
  int conv_out_channels_;

  // 卷积的输入通道数 （即输入图像的通道数）
  int conv_in_channels_;

  // 卷积的输出的空间维度 = 卷积后图像h*卷积后图像w
  int conv_out_spatial_dim_;

  // 卷积核的维度 = 输入图像的维度*卷积核的h*卷积核的w
  int kernel_dim_;

  // 在使用gropu参数的时候使用的offset
  int col_offset_;
  int output_offset_;

  // im2col的时候使用的存储空间
  Blob<Dtype> col_buffer_;

  // 将偏置扩展成矩阵的东东
  Blob<Dtype> bias_multiplier_;
```

- 成员函数，ConvolutionLayer是继承于BaseConvolutionLayer的，而BaseConvolutionLayer才是真正实现卷积及其反传的，而在BaseConvolutionLayer中的卷积的实现中有一个重要的函数就是im2col以及col2im，im2colnd以及col2imnd。前面的两个函数是二维卷积的正向和逆向过程，而后面的两个函数是n维卷积的正向和逆向过程。有关这四个函数的详细过程可以参考 (https://blog.csdn.net/xizero00/article/details/51049858)
    - conv_layer.cpp中的forward代码，我们从外至内逐步剖析代码
```
    template <typename Dtype>
    // 输入bottom层，输出top层
    void ConvolutionLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
          const vector<Blob<Dtype>*>& top) {
      const Dtype* weight = this->blobs_[0]->cpu_data();
      for (int i = 0; i < bottom.size(); ++i) {
        const Dtype* bottom_data = bottom[i]->cpu_data();
        Dtype* top_data = top[i]->mutable_cpu_data();
        // num_ = batchsize
        for (int n = 0; n < this->num_; ++n) {
          // 基类的forward_cpu_gemm函数
          // 计算的是top_data[n * this->top_dim_] =
          // weights X bottom_data[n * this->bottom_dim_]
          // 输入的是一幅图像的数据，对应的是这幅图像卷积之后的位置
          this->forward_cpu_gemm(bottom_data + n * this->bottom_dim_, weight,
              top_data + n * this->top_dim_);
          if (this->bias_term_) {
            const Dtype* bias = this->blobs_[1]->cpu_data();
            this->forward_cpu_bias(top_data + n * this->top_dim_, bias);
          }
        }
      }
    }
```
- BaseConvolutionLayer中的forwad_cpu_gemm函数
```
template <typename Dtype>
void BaseConvolutionLayer<Dtype>::forward_cpu_gemm(const Dtype* input,
    const Dtype* weights, Dtype* output, bool skip_im2col) {
  const Dtype* col_buff = input;
  if (!is_1x1_) {
    if (!skip_im2col) {
      // 如果没有1x1卷积，也没有skip_im2col
      // 则使用conv_im2col_cpu对使用卷积核滑动过程中的每一个kernel大小的图像块
      // 变成一个列向量，形成一个height=kernel_dim_的
      // width = 卷积后图像heght*卷积后图像width
      conv_im2col_cpu(input, col_buffer_.mutable_cpu_data());
    }
    col_buff = col_buffer_.cpu_data();
  }

  // 使用caffe的cpu_gemm来进行计算
  for (int g = 0; g < group_; ++g) {
      // 分组分别进行计算
      // conv_out_channels_ / group_是每个卷积组的输出的channel
      // kernel_dim_ = input channels per-group x kernel height x kernel width
      // 计算的是output[output_offset_ * g] =
      // weights[weight_offset_ * g] X col_buff[col_offset_ * g]
      // weights的形状是 [conv_out_channel x kernel_dim_]
      // col_buff的形状是[kernel_dim_ x (卷积后图像高度乘以卷积后图像宽度)]
      // 所以output的形状自然就是conv_out_channel X (卷积后图像高度乘以卷积后图像宽度)
    caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, conv_out_channels_ /
        group_, conv_out_spatial_dim_, kernel_dim_,
        (Dtype)1., weights + weight_offset_ * g, col_buff + col_offset_ * g,
        (Dtype)0., output + output_offset_ * g);
  }
}

template <typename Dtype>
void BaseConvolutionLayer<Dtype>::forward_cpu_bias(Dtype* output,
    const Dtype* bias) {
  // output = bias * bias_multiplier_
  // num_output 与 conv_out_channel是一样的
  // num_output_ X out_spatial_dim_ = num_output_ X 1    1 X out_spatial_dim_
  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, num_output_,
      out_spatial_dim_, 1, (Dtype)1., bias, bias_multiplier_.cpu_data(),
      (Dtype)1., output);
}
```

- conv_im2col_cpu将卷积核在图像上的滑动转换为了矩阵

```
inline void conv_im2col_cpu(const Dtype* data, Dtype* col_buff) {
    if (!force_nd_im2col_ && num_spatial_axes_ == 2) {
      im2col_cpu(data, conv_in_channels_,
          conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],
          kernel_shape_.cpu_data()[0], kernel_shape_.cpu_data()[1],
          pad_.cpu_data()[0], pad_.cpu_data()[1],
          stride_.cpu_data()[0], stride_.cpu_data()[1], col_buff);
    } else {
      im2col_nd_cpu(data, num_spatial_axes_, conv_input_shape_.cpu_data(),
          col_buffer_shape_.data(), kernel_shape_.cpu_data(),
          pad_.cpu_data(), stride_.cpu_data(), col_buff);
    }
  }

```

- 卷积计算的核心函数 im2col，将image图片窗口内的图像（flat）转换为一列 （在util/im2col.cpp中可以看到），通过im2col函数可以将卷积操作变成两个矩阵相乘。此优化是贾扬清对卷积操作的一个优化，正常的卷积操作如下所示
```
  //如果不用这样的操作，贾扬清有一个吐槽，对于输入大小为W*H，维度为D的blob，卷积核为M*K*K，那么如果利用for循环，会是这样的一个操作，6层for循环，计算效率是极其低下的。
  for w in 1..W
 for h in 1..H
   for x in 1..K
     for y in 1..K
       for m in 1..M
         for d in 1..D
           output(w, h, m) += input(w+x, h+y, d) * filter(m, x, y, d)
         end
       end
     end
   end
 end
end

```
- 通过im2col优化后

```
// 输入参数为：im2col_cpu(一幅图像，输入图像的channel, 输入图像的height, 输入图像的width, kernel的height, kernel的width, pad的height, pad的width, stride的height， stride的width)
//dilation:膨胀系数，卷积核膨胀是将卷积核扩张到膨胀尺度约束的尺度中，并将原卷积核没有占用的区域填充零
// 在有膨胀稀疏下，kernel_h = dilation_h * (kernel_h - 1) + 1
void im2col_cpu(const Dtype* data_im, const int channels,
    const int height, const int width, const int kernel_h, const int kernel_w,
    const int pad_h, const int pad_w,
    const int stride_h, const int stride_w,
    const int dilation_h, const int dilation_w,
    Dtype* data_col) {
  // 卷积后输出的高度
  const int output_h = (height + 2 * pad_h -
    (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1;
  // 卷积后输出的宽度
  const int output_w = (width + 2 * pad_w -
    (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1;
  //
  const int channel_size = height * width;
  for (int channel = channels; channel--; data_im += channel_size) {
    for (int kernel_row = 0; kernel_row < kernel_h; kernel_row++) {
      for (int kernel_col = 0; kernel_col < kernel_w; kernel_col++) {
        int input_row = -pad_h + kernel_row * dilation_h;
        for (int output_rows = output_h; output_rows; output_rows--) {
          // 溢出边界补0
          if (!is_a_ge_zero_and_a_lt_b(input_row, height)) {
            for (int output_cols = output_w; output_cols; output_cols--) {
              *(data_col++) = 0;
            }
          } else {
            int input_col = -pad_w + kernel_col * dilation_w;
            for (int output_col = output_w; output_col; output_col--) {
              if (is_a_ge_zero_and_a_lt_b(input_col, width)) {
                *(data_col++) = data_im[input_row * width + input_col];
              } else {
                 // 溢出边界补0
                *(data_col++) = 0;
              }
              input_col += stride_w;
            }
          }
          input_row += stride_h;
        }
      }
    }
  }
}
```

## 反向传播层
1. Loss Layer 损失层是caffe CNN的终点，损失函数（loss function， 也可以称作）可以分为两大类：分类问题的损失函数与回归问题的损失函数，常用的损失函数包括：
    - softMax cross entropy loss（softmax 交叉熵损失函数）：它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！
    - cross entropy loss （交叉熵损失函数）
    - Mean Square Loss （MSL，均方误差）

2. softMax 源码详解（参考http://onlynice.me/2018/03/03/%E5%9F%BA%E4%BA%8ELeNet%E7%BD%91%E7%BB%9C%E7%9A%84Caffe%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90-SoftmaxLoss%E5%B1%82/）

-   caffe将softmax loss分成了softmaxLayer 和softmaxWithLossLayer两层
- 在Caffe中有一个概念即为softmax_axis,即沿着哪一个轴进行softmax计算。一般Caffe满足的是N×C×H×W的计算顺序，一般达到最后的层时，例如mnist，H,W都为1，即最终的数据维度为:N×C×1×1，默认的softmax axis是1,即C对应的轴

- 前项传播

```
template <typename Dtype>
void SoftmaxLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
    const vector<Blob<Dtype>*>& top) {
  const Dtype* bottom_data = bottom[0]->cpu_data();
  Dtype* top_data = top[0]->mutable_cpu_data();
  Dtype* scale_data = scale_.mutable_cpu_data();
  // 选择softmax中的axis，从softmax的公式中我们可以get到需要在某一个维度进行求和
  int channels = bottom[0]->shape(softmax_axis_);

   // dim 表示每张图片的维度（所占的长度）
  int dim = bottom[0]->count() / outer_num_;
  caffe_copy(bottom[0]->count(), bottom_data, top_data);
  // We need to subtract the max to avoid numerical issues, compute the exp,
  // and then normalize.
  //最外边的for循环的outer_num_对应的是样本的个数。此外，inner_num_对应的是H×W。bottom的数据是存储在Blob的一个连续空间部分，所以，对于不同的样本使用i∗dim来移动指针
  for (int i = 0; i < outer_num_; ++i) {
    // initialize scale_data to the first plane
    caffe_copy(inner_num_, bottom_data + i * dim, scale_data);
    for (int j = 0; j < channels; j++) {
    //for的关键作用就是求取最大值，用来后边减去最大值防止数值溢出，每个位置都要计算10个通道的softmax值
      for (int k = 0; k < inner_num_; k++) {
        scale_data[k] = std::max(scale_data[k],
            bottom_data[i * dim + j * inner_num_ + k]);
      }
    }
    // subtraction
    caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, inner_num_,
        1, -1., sum_multiplier_.cpu_data(), scale_data, 1., top_data);
    // exponentiation
    caffe_exp<Dtype>(dim, top_data, top_data);
    // sum after exp
    caffe_cpu_gemv<Dtype>(CblasTrans, channels, inner_num_, 1.,
        top_data, sum_multiplier_.cpu_data(), 0., scale_data);
    // division
    for (int j = 0; j < channels; j++) {
      caffe_div(inner_num_, top_data, scale_data, top_data);
      top_data += inner_num_;
    }
  }
}
```


## 反向传播

```
对softmax进行求导，根据求导后公式，进行一系列计算，具体推到过程可以参考（http://onlynice.me/2018/03/03/%E5%9F%BA%E4%BA%8ELeNet%E7%BD%91%E7%BB%9C%E7%9A%84Caffe%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90-SoftmaxLoss%E5%B1%82/）
template <typename Dtype>
void SoftmaxLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
    const vector<bool>& propagate_down,
    const vector<Blob<Dtype>*>& bottom) {
  const Dtype* top_diff = top[0]->cpu_diff();
  const Dtype* top_data = top[0]->cpu_data();
  Dtype* bottom_diff = bottom[0]->mutable_cpu_diff();
  Dtype* scale_data = scale_.mutable_cpu_data();
  int channels = top[0]->shape(softmax_axis_);
  int dim = top[0]->count() / outer_num_;
  caffe_copy(top[0]->count(), top_diff, bottom_diff);
  for (int i = 0; i < outer_num_; ++i) {
    // compute dot(top_diff, top_data) and subtract them from the bottom diff
    for (int k = 0; k < inner_num_; ++k) {
      scale_data[k] = caffe_cpu_strided_dot<Dtype>(channels,
          bottom_diff + i * dim + k, inner_num_,
          top_data + i * dim + k, inner_num_);
    }
    // subtraction
    caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, inner_num_, 1,
        -1., sum_multiplier_.cpu_data(), scale_data, 1., bottom_diff + i * dim);
  }
  // elementwise multiplication
  caffe_mul(top[0]->count(), bottom_diff, top_data, bottom_diff);
}
```

- SoftmaxWithLossLayer， lossLayer是从softmax的top层取结果，进行loss的函数计算
- forward
   ```
   template <typename Dtype>
    void SoftmaxWithLossLayer<Dtype>::Forward_cpu(
        const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
    // The forward pass computes the softmax prob values.
    softmax_layer_->Forward(softmax_bottom_vec_, softmax_top_vec_);
    const Dtype* prob_data = prob_.cpu_data();
    const Dtype* label = bottom[1]->cpu_data();
    int dim = prob_.count() / outer_num_;
    int count = 0;
    Dtype loss = 0;
    for (int i = 0; i < outer_num_; ++i) {
        for (int j = 0; j < inner_num_; j++) {
            const int label_value = static_cast<int>(label[i * inner_num_ + j]);
            if (has_ignore_label_ && label_value == ignore_label_) {
                continue;
            }
            DCHECK_GE(label_value, 0);
            DCHECK_LT(label_value, prob_.shape(softmax_axis_));
            loss -= log(std::max(prob_data[i * dim + label_value * inner_num_ + j],Dtype(FLT_MIN)));
            ++count;
        }
    }
    top[0]->mutable_cpu_data()[0] = loss / get_normalizer(normalization_, count);
    if (top.size() == 2) {
        top[1]->ShareData(prob_);
    }
    }
   ```
- backward
   对loss function进行求导
   ```
   template <typename Dtype>
    void SoftmaxWithLossLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
        const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
    if (propagate_down[1]) {
        LOG(FATAL) << this->type()
                << " Layer cannot backpropagate to label inputs.";
    }
    if (propagate_down[0]) {
        Dtype* bottom_diff = bottom[0]->mutable_cpu_diff();
        const Dtype* prob_data = prob_.cpu_data();
        caffe_copy(prob_.count(), prob_data, bottom_diff);
        const Dtype* label = bottom[1]->cpu_data();
        int dim = prob_.count() / outer_num_;
        int count = 0;
        for (int i = 0; i < outer_num_; ++i) {
        for (int j = 0; j < inner_num_; ++j) {
            const int label_value = static_cast<int>(label[i * inner_num_ + j]);
            if (has_ignore_label_ && label_value == ignore_label_) {
            for (int c = 0; c < bottom[0]->shape(softmax_axis_); ++c) {
                bottom_diff[i * dim + c * inner_num_ + j] = 0;
            }
            } else {
            bottom_diff[i * dim + label_value * inner_num_ + j] -= 1;
            ++count;
            }
        }
        }
        // Scale gradient
        Dtype loss_weight = top[0]->cpu_diff()[0] /
                            get_normalizer(normalization_, count);
        caffe_scal(prob_.count(), loss_weight, bottom_diff);
    }
    }

   ```
